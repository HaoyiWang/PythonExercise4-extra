{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4495588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\666\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "drop() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m lda_model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mLdaModel(corpus, id2word\u001b[38;5;241m=\u001b[39mdictionary, num_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, passes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Visualize the topics\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m vis_data \u001b[38;5;241m=\u001b[39m \u001b[43mgensimvis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlda_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39mdisplay(vis_data)\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\gensim.py:119\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03mthe data structures needed for the visualization.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03mSee `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m opts \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mmerge(_extract_data(topic_model, corpus, dictionary, doc_topic_dist), kwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvis_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\_prepare.py:398\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m## Quick fix for red bar width bug.  We calculate the\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m## term frequencies internally, using the topic term distributions and the\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m## topic frequencies, rather than using the user-supplied term frequencies.\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m## For a detailed discussion, see: https://github.com/cpsievert/LDAvis/pull/41\u001b[39;00m\n\u001b[0;32m    396\u001b[0m term_frequency \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(term_topic_freq, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 398\u001b[0m topic_info         \u001b[38;5;241m=\u001b[39m \u001b[43m_topic_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic_term_dists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic_proportion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_topic_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m token_table        \u001b[38;5;241m=\u001b[39m _token_table(topic_info, term_topic_freq, vocab, term_frequency)\n\u001b[0;32m    400\u001b[0m topic_coordinates \u001b[38;5;241m=\u001b[39m _topic_coordinates(mds, topic_term_dists, topic_proportion)\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\_prepare.py:228\u001b[0m, in \u001b[0;36m_topic_info\u001b[1;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs)\u001b[0m\n\u001b[0;32m    225\u001b[0m saliency \u001b[38;5;241m=\u001b[39m term_proportion \u001b[38;5;241m*\u001b[39m distinctiveness\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Order the terms for the \"default\" view by decreasing saliency:\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m default_term_info  \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msaliency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTerm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFreq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m   \u001b[49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m   \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# Rounding Freq and Total to integer values to match LDAvis code:\u001b[39;00m\n\u001b[0;32m    234\u001b[0m default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: drop() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from gensim import corpora, models\n",
    "\n",
    "# Enable Jupyter Notebook display\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# Load the \"Alice's Adventures in Wonderland\" text from NLTK Gutenberg corpus\n",
    "nltk.download('gutenberg')\n",
    "alice_raw = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# Preprocess the text\n",
    "sentences = nltk.sent_tokenize(alice_raw)\n",
    "texts = [nltk.word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "\n",
    "# Create dictionary and corpus\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Perform topic modeling using LDA\n",
    "lda_model = models.LdaModel(corpus, id2word=dictionary, num_topics=5, passes=15)\n",
    "\n",
    "# Visualize the topics\n",
    "vis_data = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a414d7c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\666\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "drop() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m lda_model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mLdaModel(corpus, id2word\u001b[38;5;241m=\u001b[39mdictionary, num_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, passes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Visualize the topics\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m vis_data \u001b[38;5;241m=\u001b[39m \u001b[43mpyLDAvis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlda_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39mdisplay(vis_data)\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\gensim.py:119\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03mthe data structures needed for the visualization.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03mSee `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m opts \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mmerge(_extract_data(topic_model, corpus, dictionary, doc_topic_dist), kwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvis_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\_prepare.py:398\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m## Quick fix for red bar width bug.  We calculate the\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m## term frequencies internally, using the topic term distributions and the\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m## topic frequencies, rather than using the user-supplied term frequencies.\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m## For a detailed discussion, see: https://github.com/cpsievert/LDAvis/pull/41\u001b[39;00m\n\u001b[0;32m    396\u001b[0m term_frequency \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(term_topic_freq, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 398\u001b[0m topic_info         \u001b[38;5;241m=\u001b[39m \u001b[43m_topic_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic_term_dists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic_proportion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_topic_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m token_table        \u001b[38;5;241m=\u001b[39m _token_table(topic_info, term_topic_freq, vocab, term_frequency)\n\u001b[0;32m    400\u001b[0m topic_coordinates \u001b[38;5;241m=\u001b[39m _topic_coordinates(mds, topic_term_dists, topic_proportion)\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\_prepare.py:228\u001b[0m, in \u001b[0;36m_topic_info\u001b[1;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs)\u001b[0m\n\u001b[0;32m    225\u001b[0m saliency \u001b[38;5;241m=\u001b[39m term_proportion \u001b[38;5;241m*\u001b[39m distinctiveness\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Order the terms for the \"default\" view by decreasing saliency:\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m default_term_info  \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msaliency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTerm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFreq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m   \u001b[49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m   \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# Rounding Freq and Total to integer values to match LDAvis code:\u001b[39;00m\n\u001b[0;32m    234\u001b[0m default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: drop() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from gensim import corpora, models\n",
    "\n",
    "# Enable Jupyter Notebook display\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# Load the \"Alice's Adventures in Wonderland\" text from NLTK Gutenberg corpus\n",
    "nltk.download('gutenberg')\n",
    "alice_raw = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# Preprocess the text\n",
    "sentences = nltk.sent_tokenize(alice_raw)\n",
    "texts = [nltk.word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "\n",
    "# Create dictionary and corpus\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Perform topic modeling using LDA\n",
    "lda_model = models.LdaModel(corpus, id2word=dictionary, num_topics=5, passes=10)\n",
    "\n",
    "# Visualize the topics\n",
    "vis_data = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "757b7a7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "drop() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m\n\u001b[0;32m     20\u001b[0m num_topics \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     21\u001b[0m lda_model \u001b[38;5;241m=\u001b[39m LdaModel(corpus\u001b[38;5;241m=\u001b[39mcorpus,\n\u001b[0;32m     22\u001b[0m                      id2word\u001b[38;5;241m=\u001b[39mdictionary,\n\u001b[0;32m     23\u001b[0m                      num_topics\u001b[38;5;241m=\u001b[39mnum_topics)\n\u001b[1;32m---> 25\u001b[0m lda_vis \u001b[38;5;241m=\u001b[39m \u001b[43mgensimvis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlda_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39mshow(lda_vis)\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\gensim.py:119\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03mthe data structures needed for the visualization.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03mSee `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m opts \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mmerge(_extract_data(topic_model, corpus, dictionary, doc_topic_dist), kwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvis_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\_prepare.py:398\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m## Quick fix for red bar width bug.  We calculate the\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m## term frequencies internally, using the topic term distributions and the\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m## topic frequencies, rather than using the user-supplied term frequencies.\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m## For a detailed discussion, see: https://github.com/cpsievert/LDAvis/pull/41\u001b[39;00m\n\u001b[0;32m    396\u001b[0m term_frequency \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(term_topic_freq, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 398\u001b[0m topic_info         \u001b[38;5;241m=\u001b[39m \u001b[43m_topic_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic_term_dists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic_proportion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_topic_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m token_table        \u001b[38;5;241m=\u001b[39m _token_table(topic_info, term_topic_freq, vocab, term_frequency)\n\u001b[0;32m    400\u001b[0m topic_coordinates \u001b[38;5;241m=\u001b[39m _topic_coordinates(mds, topic_term_dists, topic_proportion)\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\_prepare.py:228\u001b[0m, in \u001b[0;36m_topic_info\u001b[1;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs)\u001b[0m\n\u001b[0;32m    225\u001b[0m saliency \u001b[38;5;241m=\u001b[39m term_proportion \u001b[38;5;241m*\u001b[39m distinctiveness\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Order the terms for the \"default\" view by decreasing saliency:\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m default_term_info  \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msaliency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTerm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFreq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m   \u001b[49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m   \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# Rounding Freq and Total to integer values to match LDAvis code:\u001b[39;00m\n\u001b[0;32m    234\u001b[0m default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: drop() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "#pyLDAvis.enable_notebook()\n",
    "#nltk.download('gutenberg')\n",
    "\n",
    "alice_corpus = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "alice_tokens = nltk.word_tokenize(alice_corpus)\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "alice_tokens = [token for token in alice_tokens if token.lower() not in stopwords and token.isalpha()]\n",
    "\n",
    "dictionary = corpora.Dictionary([alice_tokens])\n",
    "corpus = [dictionary.doc2bow(alice_tokens)]\n",
    "\n",
    "num_topics = 5\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                     id2word=dictionary,\n",
    "                     num_topics=num_topics)\n",
    "\n",
    "lda_vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "pyLDAvis.show(lda_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2852ed62",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "drop() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 25\u001b[0m\n\u001b[0;32m     20\u001b[0m num_topics \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     21\u001b[0m lda_model \u001b[38;5;241m=\u001b[39m LdaModel(corpus\u001b[38;5;241m=\u001b[39mcorpus,\n\u001b[0;32m     22\u001b[0m                      id2word\u001b[38;5;241m=\u001b[39mdictionary,\n\u001b[0;32m     23\u001b[0m                      num_topics\u001b[38;5;241m=\u001b[39mnum_topics)\n\u001b[1;32m---> 25\u001b[0m lda_vis \u001b[38;5;241m=\u001b[39m \u001b[43mgensimvis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlda_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39mshow(lda_vis)\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\gensim.py:119\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03mthe data structures needed for the visualization.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03mSee `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m opts \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mmerge(_extract_data(topic_model, corpus, dictionary, doc_topic_dist), kwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvis_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\_prepare.py:398\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m## Quick fix for red bar width bug.  We calculate the\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m## term frequencies internally, using the topic term distributions and the\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m## topic frequencies, rather than using the user-supplied term frequencies.\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m## For a detailed discussion, see: https://github.com/cpsievert/LDAvis/pull/41\u001b[39;00m\n\u001b[0;32m    396\u001b[0m term_frequency \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(term_topic_freq, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 398\u001b[0m topic_info         \u001b[38;5;241m=\u001b[39m \u001b[43m_topic_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic_term_dists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic_proportion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_topic_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m token_table        \u001b[38;5;241m=\u001b[39m _token_table(topic_info, term_topic_freq, vocab, term_frequency)\n\u001b[0;32m    400\u001b[0m topic_coordinates \u001b[38;5;241m=\u001b[39m _topic_coordinates(mds, topic_term_dists, topic_proportion)\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\_prepare.py:228\u001b[0m, in \u001b[0;36m_topic_info\u001b[1;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs)\u001b[0m\n\u001b[0;32m    225\u001b[0m saliency \u001b[38;5;241m=\u001b[39m term_proportion \u001b[38;5;241m*\u001b[39m distinctiveness\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Order the terms for the \"default\" view by decreasing saliency:\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m default_term_info  \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msaliency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTerm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFreq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m   \u001b[49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m   \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# Rounding Freq and Total to integer values to match LDAvis code:\u001b[39;00m\n\u001b[0;32m    234\u001b[0m default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: drop() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "#pyLDAvis.enable_notebook()\n",
    "#nltk.download('gutenberg')\n",
    "\n",
    "alice_corpus = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "alice_tokens = nltk.word_tokenize(alice_corpus)\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "alice_tokens = [token for token in alice_tokens if token.lower() not in stopwords and token.isalpha()]\n",
    "\n",
    "dictionary = corpora.Dictionary([alice_tokens])\n",
    "corpus = [dictionary.doc2bow(alice_tokens)]\n",
    "\n",
    "num_topics = 5\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                     id2word=dictionary,\n",
    "                     num_topics=num_topics)\n",
    "\n",
    "lda_vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "pyLDAvis.show(lda_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ac44b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "drop() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m\n\u001b[0;32m     20\u001b[0m num_topics \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     21\u001b[0m lda_model \u001b[38;5;241m=\u001b[39m LdaModel(corpus\u001b[38;5;241m=\u001b[39mcorpus,\n\u001b[0;32m     22\u001b[0m                      id2word\u001b[38;5;241m=\u001b[39mdictionary,\n\u001b[0;32m     23\u001b[0m                      num_topics\u001b[38;5;241m=\u001b[39mnum_topics)\n\u001b[1;32m---> 25\u001b[0m lda_vis \u001b[38;5;241m=\u001b[39m \u001b[43mgensimvis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlda_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdictionary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39mshow(lda_vis)\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\gensim.py:119\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03mthe data structures needed for the visualization.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03mSee `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m opts \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mmerge(_extract_data(topic_model, corpus, dictionary, doc_topic_dist), kwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvis_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\_prepare.py:398\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m## Quick fix for red bar width bug.  We calculate the\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m## term frequencies internally, using the topic term distributions and the\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m## topic frequencies, rather than using the user-supplied term frequencies.\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m## For a detailed discussion, see: https://github.com/cpsievert/LDAvis/pull/41\u001b[39;00m\n\u001b[0;32m    396\u001b[0m term_frequency \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(term_topic_freq, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 398\u001b[0m topic_info         \u001b[38;5;241m=\u001b[39m \u001b[43m_topic_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic_term_dists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic_proportion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_topic_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m token_table        \u001b[38;5;241m=\u001b[39m _token_table(topic_info, term_topic_freq, vocab, term_frequency)\n\u001b[0;32m    400\u001b[0m topic_coordinates \u001b[38;5;241m=\u001b[39m _topic_coordinates(mds, topic_term_dists, topic_proportion)\n",
      "File \u001b[1;32mc:\\users\\666\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pyLDAvis\\_prepare.py:228\u001b[0m, in \u001b[0;36m_topic_info\u001b[1;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs)\u001b[0m\n\u001b[0;32m    225\u001b[0m saliency \u001b[38;5;241m=\u001b[39m term_proportion \u001b[38;5;241m*\u001b[39m distinctiveness\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Order the terms for the \"default\" view by decreasing saliency:\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m default_term_info  \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msaliency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTerm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFreq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m   \u001b[49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m   \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# Rounding Freq and Total to integer values to match LDAvis code:\u001b[39;00m\n\u001b[0;32m    234\u001b[0m default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: drop() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "#pyLDAvis.enable_notebook()\n",
    "#nltk.download('gutenberg')\n",
    "\n",
    "alice_corpus = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "alice_tokens = nltk.word_tokenize(alice_corpus)\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "alice_tokens = [token for token in alice_tokens if token.lower() not in stopwords and token.isalpha()]\n",
    "\n",
    "dictionary = corpora.Dictionary([alice_tokens])\n",
    "corpus = [dictionary.doc2bow(alice_tokens)]\n",
    "\n",
    "num_topics = 5\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                     id2word=dictionary,\n",
    "                     num_topics=num_topics)\n",
    "\n",
    "lda_vis = gensimvis.prepare(topic_model=lda_model, corpus=corpus, dictionary=dictionary)\n",
    "\n",
    "pyLDAvis.show(lda_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad89ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
